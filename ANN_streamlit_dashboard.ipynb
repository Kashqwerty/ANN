{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfhNYNPa4xY5",
        "outputId": "ff107e90-4b05-4447-b081-8f444889dc95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-03-31 11:17:25.503 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-03-31 11:17:25.507 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-03-31 11:17:25.510 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-03-31 11:17:25.512 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-03-31 11:17:25.521 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-03-31 11:17:25.522 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-03-31 11:17:25.523 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-03-31 11:17:25.527 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-03-31 11:17:25.529 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ],
      "source": [
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, InputLayer\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Unique Title for the Dashboard\n",
        "st.title(\"ðŸ¤– Interactive ANN Prediction & Visualization Dashboard\")\n",
        "\n",
        "# Upload dataset section\n",
        "st.markdown(\"### ðŸ“‚ Upload Your CSV Dataset\")\n",
        "uploaded_file = st.file_uploader(\"Choose a CSV file\", type=['csv'])\n",
        "\n",
        "if uploaded_file is not None:\n",
        "    # Load and preview dataset\n",
        "    data = pd.read_csv(uploaded_file)\n",
        "    st.markdown(\"#### ðŸ” Dataset Preview\")\n",
        "    st.dataframe(data.head())\n",
        "    st.markdown(\"#### ðŸ“Š Dataset Summary\")\n",
        "    st.write(data.describe())\n",
        "\n",
        "    # Select target column and display class distribution\n",
        "    target_col = st.selectbox(\"ðŸŽ¯ Select Target Column\", data.columns)\n",
        "    feature_cols = [col for col in data.columns if col != target_col]\n",
        "\n",
        "    st.markdown(\"#### ðŸ“ˆ Target Column Distribution\")\n",
        "    fig_dist, ax_dist = plt.subplots()\n",
        "    data[target_col].value_counts().plot(kind=\"bar\", ax=ax_dist)\n",
        "    ax_dist.set_xlabel(\"Classes\")\n",
        "    ax_dist.set_ylabel(\"Frequency\")\n",
        "    st.pyplot(fig_dist)\n",
        "\n",
        "    # Data Preprocessing\n",
        "    X = data[feature_cols].copy()\n",
        "    y = data[target_col].copy()\n",
        "\n",
        "    # Encode categorical features if needed\n",
        "    for col in X.select_dtypes(include=['object']).columns:\n",
        "        X[col] = LabelEncoder().fit_transform(X[col])\n",
        "    if y.dtype == 'object':\n",
        "        y = LabelEncoder().fit_transform(y)\n",
        "\n",
        "    # Scale numerical features\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    # Sidebar: Choose test size ratio\n",
        "    test_size = st.sidebar.slider(\"Test Data Ratio\", 0.1, 0.4, 0.2, step=0.05)\n",
        "\n",
        "    # Split dataset\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=test_size, random_state=2224)\n",
        "\n",
        "    # Sidebar: Model Hyperparameters\n",
        "    st.sidebar.markdown(\"### âš™ï¸ Model Hyperparameters\")\n",
        "    num_layers = st.sidebar.slider(\"Number of Hidden Layers\", 1, 5, 2)\n",
        "    neurons_per_layer = []\n",
        "    activation_functions = []\n",
        "    for i in range(num_layers):\n",
        "        neurons = st.sidebar.slider(f\"Neurons in Hidden Layer {i+1}\", 5, 150, 50, step=5)\n",
        "        activation = st.sidebar.selectbox(f\"Activation Function for Layer {i+1}\", ['relu', 'tanh', 'sigmoid'], key=f\"act_{i}\")\n",
        "        neurons_per_layer.append(neurons)\n",
        "        activation_functions.append(activation)\n",
        "\n",
        "    optimizer_choice = st.sidebar.selectbox(\"Optimizer\", ['adam', 'sgd', 'rmsprop'])\n",
        "    lr = st.sidebar.number_input(\"Learning Rate\", value=0.001, min_value=0.0001, max_value=0.1, step=0.0001, format=\"%.4f\")\n",
        "    loss_func = st.sidebar.selectbox(\"Loss Function\", ['binary_crossentropy', 'mean_squared_error', 'hinge'])\n",
        "    dropout_rate = st.sidebar.slider(\"Dropout Rate\", 0.0, 0.5, 0.2)\n",
        "    epochs = st.sidebar.slider(\"Epochs\", 10, 200, 50, step=10)\n",
        "    batch_size = st.sidebar.slider(\"Batch Size\", 8, 128, 32, step=8)\n",
        "    early_stopping = st.sidebar.checkbox(\"Enable Early Stopping\", value=False)\n",
        "\n",
        "    # Train Model Button\n",
        "    if st.button(\"ðŸš€ Train the ANN Model\"):\n",
        "        # Build the ANN model\n",
        "        model = Sequential()\n",
        "        model.add(InputLayer(input_shape=(X_train.shape[1],)))\n",
        "        for i in range(num_layers):\n",
        "            model.add(Dense(units=neurons_per_layer[i], activation=activation_functions[i]))\n",
        "            model.add(Dropout(rate=dropout_rate))\n",
        "        model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "        # Select optimizer\n",
        "        if optimizer_choice == \"adam\":\n",
        "            optimizer_obj = Adam(learning_rate=lr)\n",
        "        elif optimizer_choice == \"sgd\":\n",
        "            optimizer_obj = SGD(learning_rate=lr)\n",
        "        else:\n",
        "            optimizer_obj = RMSprop(learning_rate=lr)\n",
        "\n",
        "        model.compile(loss=loss_func, optimizer=optimizer_obj, metrics=['accuracy'])\n",
        "\n",
        "        st.markdown(\"#### ðŸ”§ Model Configuration\")\n",
        "        st.write(\"Optimizer:\", optimizer_choice)\n",
        "        st.write(\"Learning Rate:\", lr)\n",
        "        st.write(\"Neurons per Layer:\", neurons_per_layer)\n",
        "        st.write(\"Dropout Rate:\", dropout_rate)\n",
        "        st.write(\"Epochs:\", epochs)\n",
        "        st.write(\"Batch Size:\", batch_size)\n",
        "\n",
        "        # Optional early stopping callback\n",
        "        callbacks = []\n",
        "        if early_stopping:\n",
        "            early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n",
        "            callbacks.append(early_stop)\n",
        "\n",
        "        # Train the model\n",
        "        with st.spinner('Training the model... Please wait!'):\n",
        "            history = model.fit(X_train, y_train,\n",
        "                                validation_data=(X_test, y_test),\n",
        "                                epochs=epochs,\n",
        "                                batch_size=batch_size,\n",
        "                                callbacks=callbacks,\n",
        "                                verbose=1)\n",
        "        st.success(\"ðŸŽ‰ Model Training Completed!\")\n",
        "\n",
        "        # Plot Loss History\n",
        "        fig_loss, ax_loss = plt.subplots()\n",
        "        ax_loss.plot(history.history['loss'], label='Training Loss')\n",
        "        ax_loss.plot(history.history['val_loss'], label='Validation Loss')\n",
        "        ax_loss.set_xlabel(\"Epochs\")\n",
        "        ax_loss.set_ylabel(\"Loss\")\n",
        "        ax_loss.set_title(\"Loss over Epochs\")\n",
        "        ax_loss.legend()\n",
        "        st.pyplot(fig_loss)\n",
        "\n",
        "        # Plot Accuracy History\n",
        "        fig_acc, ax_acc = plt.subplots()\n",
        "        ax_acc.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "        ax_acc.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "        ax_acc.set_xlabel(\"Epochs\")\n",
        "        ax_acc.set_ylabel(\"Accuracy\")\n",
        "        ax_acc.set_title(\"Accuracy over Epochs\")\n",
        "        ax_acc.legend()\n",
        "        st.pyplot(fig_acc)\n",
        "\n",
        "        # Evaluate the model on test data\n",
        "        st.markdown(\"### ðŸ“ˆ Model Evaluation on Test Data\")\n",
        "        test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "        st.write(f\"**Test Loss:** {test_loss:.4f}\")\n",
        "        st.write(f\"**Test Accuracy:** {test_acc * 100:.2f}%\")\n",
        "\n",
        "        # Generate predictions and compute confusion matrix\n",
        "        y_pred_prob = model.predict(X_test)\n",
        "        y_pred = (y_pred_prob > 0.5).astype(\"int32\")\n",
        "        cm = confusion_matrix(y_test, y_pred)\n",
        "        st.markdown(\"#### ðŸ¤– Confusion Matrix\")\n",
        "        fig_cm, ax_cm = plt.subplots()\n",
        "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", ax=ax_cm)\n",
        "        ax_cm.set_xlabel(\"Predicted\")\n",
        "        ax_cm.set_ylabel(\"Actual\")\n",
        "        st.pyplot(fig_cm)\n",
        "\n",
        "        # Display classification report\n",
        "        st.markdown(\"#### ðŸ“‹ Classification Report\")\n",
        "        report = classification_report(y_test, y_pred, output_dict=True)\n",
        "        st.dataframe(pd.DataFrame(report).transpose())\n",
        "\n",
        "\n"
      ]
    }
  ]
}